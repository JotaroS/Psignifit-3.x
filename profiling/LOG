Profiling session Sun 19th December
===================================

This is profiling session to rerun profile_mcmc on its initial and optimized
commits, and to record the improvement, mainly to test if the profiling
branch/subdirectory strategy will work in practice:

Testing Machine:
  x61s ThinkPad
  Intel(R) Core(TM)2 Duo CPU  L7500  @ 1.60GHz (Two core)
  3 GB Memory
  Gentoo Linux

Profile script:
  profile_mcmc.cc
  1e6 MCMC Samples to be drawn

First Commit:
-------------
  commit eb57407e3518c2a95b08f7428d76bf5996731fa9
  Author: Ingo Fründ <ingo.fruend@googlemail.com>
  Date:   Wed Dec 15 17:13:18 2010 +0100

      C++[OPT] added profile_mcmc

Times:
  540.75s user 0.68s system 99% cpu 9:06.23 total
  609.68s user 1.53s system 98% cpu 10:21.38 total
  613.86s user 1.47s system 98% cpu 10:25.02 total

  Average: 588.09s ~~ 9:48

Files:
  profile_mcmc1.gmon.out
  profile_mcmc1.text
  profile_mcmc1.png

Discussion:
  As can be seen from the text file, the PsiData constructor and the rngcall are
  the worst bottlenecks. Since this is a post mortem reconstruction we can say
  that these were both optimized and will be discussed next.

Second Commit:
--------------
  commit 38ae7b283737ad6ae9b5f33d0ab9434d7ddfd665
  Author: Ingo Fründ <ingo.fruend@googlemail.com>
  Date:   Wed Dec 15 17:13:53 2010 +0100

      C++[RF] moving datasets out of MCMC loop
Times:
  203.45s user 0.64s system 98% cpu 3:27.04 total
  229.54s user 0.74s system 98% cpu 3:54.13 total
  241.75s user 0.84s system 98% cpu 4:06.98 total

  Average: 224.91 ~~ 3:45.00

Files:
  profile_mcmc2.gmon.out
  profile_mcmc2.text
  profile_mcmc2.png

Discussion:
  Already obvious from the overall execution time reduction by 1/3. Further
  evidence is from text output which shows that only 1/3 time is spent in the
  PsiData constructor. The graph indicates that the
  pseudo-random-number-generator is now much more a bottleneck than before.
  Again, since this is post-mortem, we know that optimizing this will yield
  further improvement.

Third Commit:
-------------
  commit 696a244abcd770bed588371492f64b128d976638
  Author: Ingo Fründ <ingo.fruend@googlemail.com>
  Date:   Thu Dec 16 15:01:25 2010 +0100

      C++[RF-NF] using Mersenne Twister for random number generation

Times:
  177.51s user 0.39s system 99% cpu 2:59.36 total
  222.59s user 0.33s system 99% cpu 3:44.62 total
  217.76s user 0.30s system 99% cpu 3:39.88 total

  Average : 205.95 ~~ 3:25

Files:
  profile_mcmc3.gmon.out
  profile_mcmc3.text
  profile_mcmc3.png

Discussion:
  Although the text files indicate differently, there is no significant (read:
  order of magnitude) benefit from using the mersenne twister. The second run
  lists 41.06% attributable to PsiRandom::rngcall(), and the third 13.74%
  attributable to genrand_int32(). One might assume therefore that a 3 fold
  increase has been achieved, but the overall execution time says otherwise. The
  difference in profiler output is still to be understood. Looking at the
  graphical output yielded no further insights. Although it may just be that it
  is faster, just the speed up is within the fluctuation limits, e.g. 4 min -> 3
  min. Perhaps another test with more samples should be conducted? Perhaps using
  a machine that has less stuff, running on it?

Profiling Session Mon 20 Dec
============================

When running a pilot simulation in December 2010 I saw certain jobs that took
around 45 Minutes per single MCMC run. Since the software had not been this slow
before, I decided to get to the bottom of this. The plan is to use the python
cProfile and google perftools to look for bottlenecks and/or bugs.

Testing Machine:
  x61s ThinkPad
  Intel(R) Core(TM)2 Duo CPU  L7500  @ 1.60GHz (Two core)
  3 GB Memory
  Gentoo Linux

Profile script:
  run_mcmc_single.py

First Commit
------------
  commit 93d4f0c8a88f66d4c7e3e730c3995df6bb17e3a1
  Author: Ingo Fründ <ingo.fruend@googlemail.com>
  Date:   Thu Dec 16 15:33:10 2010 +0100

      changelog entry for upload

  Tag: snap-2010-12-16 (most recent snapshot at time of writing)

Times:
   2401.92s user 1.80s system 98% cpu 40:28.75 total
   4220.52s user 2.95s system 99% cpu 1:11:04.25 total
   1820.28s user 1.09s system 99% cpu 30:39.43 total

   Average ~ 46 Minutes

Files:
  run_mcmc_single1.stats
  run_mcmc_single1.png

Discussion:
  The timing roughly corresponds to what was observed on the cluster. However
  since the mapestimate was different each time, even though the prng is
  _supposed_ to be seeded the same each time, would suggest that there is a bug
  there somewhere, either in the initialisation routine, or perhaps it is simply
  not called. As for the profiling output the graph clearly shows that 75% of
  the time is spent in __tunesampler, and half the time is spent doing a
  jackknife, that would be somewhere around 20 minutes. This points in the right
  direction to optimize the code. Note here that this is only profiling the
  python level, a full profiling run of the entire code, including c-extension
  will done at a later stage. Next I would like to check that the code was not
  this slow when I ran the simulation from August to October.

Second Commit
-------------
  commit e20233e9a097649ca72c5ea0ac06ae8960af1d1f
  Merge: cecdd2b 08b1c91
  Author: Valentin Haenel <valentin.haenel@gmx.de>
  Date:   Wed Aug 11 15:24:20 2010 +0200

      Merge branch 'val/master'

Times:
  456.71s user 0.39s system 99% cpu 7:40.88 total
  259.41s user 0.35s system 98% cpu 4:23.27 total
  483.60s user 0.59s system 98% cpu 8:09.86 total

  Average ~~ 6:40

Files:
  run_mcmc_single2.stats
  run_mcmc_single2.png

Discussion:
  This is a much older version of the code, namely the one i used to run my
  simulations from aug-oct 2010, and the many checks after that.

  First, the seeding problem is already there, i get different mapestimates all
  the time. Second, runs that just bailed out with 600 samples were discarded (in
  this case about half) due to a known bug, where the chain does not move, and
  hence we obtain bad coverage due to zero length condfidence intervals. Third,
  even though i didn't check convergence CI size etc... i am pretty confident
  that this version yielded some reasonable results (i have coverage plots
  hanging in my office). Fourth, the time for this version of psignifit is much
  reduced, it doesn't quite explain how 1000 of these should have taken 6
  Days(!) on the cluster (well its at least on the order of 4-5). Its better
  than the current proposed time of 20 Days for 1000 of these. Fifth, the
  callgraph shows something slightly more sane, the bulk of the time is spent
  sampling, in fact 20% are spent in __determine_optimum_sampling, and the rest
  in the real sample method.

Suggested Actions:
  fix seeding problem, the run_mcmc_single.py should give the same results every
  time it is run.
  fix too much time spent in __tunesampler
  then profile using gperf-tools and valgrind
  
Further Notes:
  The problem with seeding is such that the data is generated with the scipy
  random number generator, this must be seeded sepeartely.

Profiling Session Tue 21 Dec
============================

After working out that numpy needs to be seeded too, I can now make
run_mcmc_single.py repeat results. I thus selected 3 seeds using
val-sim-oct-2010, one that bails out after ~ one minute, one that takes about 5,
and one that takes about 10. The plan is to run this on the old commit, get
timings, and then try and see what happens when i run it against current master.
Some fixes (well, more like backrolls) were done today in order to reduce the
insane runtime of 45 minutes which we was showen in the last session. There are
two goals: one: see if the new code runs faster, two: see if there are still
zero length confidence intervals. The second check, may or may not be
trustworthy, since the prng has changed to mersenne twister. This time i will
run a best of three, without profiling information, and then run a 4th time to
generate the callgraph. Also datetime has been leveraged in order to get timing
information about each of the three mcmc runs seperately, so timing will be more
of a matrix this time around.

Profile Script
  three_mcmc.py

First Commit
-------------
  commit e20233e9a097649ca72c5ea0ac06ae8960af1d1f
  Merge: cecdd2b 08b1c91
  Author: Valentin Haenel <valentin.haenel@gmx.de>
  Date:   Wed Aug 11 15:24:20 2010 +0200

      Merge branch 'val/master'

Times:
  (seeds 3, 4 and 7)
  run one
    0:00:54.137857
    0:05:26.563549
    0:08:43.997391
  run two
    0:01:10.550657
    0:05:35.199199
    0:08:47.709018
  run three
    0:01:03.010207
    0:05:31.978105
    0:08:43.092953

Second Commit
-------------
  commit 77b9ff56af21c435e1e152b11d26554ce29c658d
  Author: Ingo Fründ <ingo.fruend@googlemail.com>
  Date:   Tue Dec 21 19:15:55 2010 +0100

      changelog entry for upload

Times:
    0:00:32.787996
    0:13:51.024845
    0:03:42.855861

    0:00:49.850348
    0:14:23.284992
    0:03:47.069281

    0:00:44.672713
    0:14:28.018174
    0:03:47.978921

Discussion:
  Well, as we can clearly see clocking MCMC samplers is difficult if the prng
  changes, since they are so wildely variable, even if the input data is the
  same. The zero length confidence interval may not have been detected, which is
  bad, but a seperate check should be done to ensure this. Apart from that its
  not really clear from the run-time if an acceleration was really achieved,
  since its difficult to run the same chain.

